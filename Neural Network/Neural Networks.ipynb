{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Neural Networks\n",
    "\n",
    "As you are reading this article, the very same brain that sometimes forgets why you walked into a room is magically translating these pixels into letters, words, and sentences — a feat that puts the world’s fastest supercomputers to shame. Within the brain, thousands of neurons are firing at incredible speed and accuracy to help us recognize text, images, and the world at large.\n",
    "\n",
    "<img src=\"images/JEFlGfz.png\" width=\"800\" height=\"400\">\n",
    "\n",
    "\n",
    "A neural network is a programming model that simulates the human brain. Let’s explore how it came into existence.\n",
    "\n",
    "## The Birth of an Artificial Neuron\n",
    "\n",
    "Computers have been designed to excel at number-crunching tasks, something that most humans find terrifying. On the other hand, humans are naturally wired to effortlessly recognize objects and patterns, something that computers find difficult.\n",
    "\n",
    "This juxtaposition brought up two important questions in the 1950s:\n",
    "\n",
    "“How can computers be better at solving problems that humans find effortless?”\n",
    "“How can computers solve such problems in the way a human brain does?”\n",
    "In 1957, Frank Rosenblatt explored the second question and invented the Perceptron algorithm that allowed an artificial neuron to simulate a biological neuron! The artificial neuron could take in an input, process it based on some rules, and fire a result. But computers had been doing this for years — what was so remarkable?\n",
    "\n",
    "<img src=\"images/perceptron.png\" width=\"800\" height=\"400\">\n",
    "\n",
    "\n",
    "There was a final step in the Perceptron algorithm that would give rise to the incredibly mysterious world of Neural Networks — the artificial neuron could train itself based on its own results, and fire better results in the future. In other words, it could learn by trial and error, just like a biological neuron.\n",
    "\n",
    "## More Neurons\n",
    "\n",
    "The Perceptron Algorithm used multiple artificial neurons, or perceptrons, for image recognition tasks and opened up a whole new way to solve computational problems. However, as it turns out, this wasn’t enough to solve a wide range of problems, and interest in the Perceptron Algorithm along with Neural Networks waned for many years.\n",
    "\n",
    "But many years later, the neurons fired back.\n",
    "\n",
    "<img src=\"images/EmaJ5JU.gif\" width=\"800\" height=\"400\">\n",
    "\n",
    "\n",
    "It was found out that creating multiple layers of neurons — with one layer feeding its output to the next layer as input — could process a wide range of inputs, make complex decisions, and still produce meaningful results. With some tweaks, the algorithm became known as the Multilayer Perceptron, which led to the rise of Feedforward Neural Networks.\n",
    "\n",
    "60 Years Later…\n",
    "\n",
    "With Feedforward Networks, the results improved. But it was only recently, with the development of high-speed processors, that neural networks finally got the necessary computing power to seamlessly integrate into daily human life.\n",
    "\n",
    "Today, the applications of neural networks have become widespread — from simple tasks like speech recognition to more complicated tasks like self-driving vehicles.\n",
    "\n",
    "In 2012, Alex Krizhevsky and his team at University of Toronto entered the ImageNet competition (the annual Olympics of computer vision) and trained a deep convolutional neural network [pdf]. No one truly understood how it made the decisions it did, but it worked better than any other traditional classifier, by a huge 10.8% margin.\n",
    "\n",
    "## Summary\n",
    "\n",
    "The neurons have come a long way. They have braved the AI winter and remained patient amidst the lack of computing power in the 20th century. They have now taken the world by storm and deservedly so.\n",
    "\n",
    "Neural networks are ridiculously good at generating results but also mysteriously complex; the apparent complexity of the decision-making process makes it difficult to say exactly how neural networks arrive at their superhuman level of accuracy.\n",
    "\n",
    "Let’s dive into the world of Neural Networks and relish in all its mystery!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Perceptron?\n",
    "\n",
    "Similar to how atoms are the building blocks of matter and how microprocessors are the building blocks of a computer, perceptrons are the building blocks of Neural Networks.\n",
    "\n",
    "If you look closely, you might notice that the word “perceptron” is a combination of two words:\n",
    "\n",
    "* Perception (noun) the ability to sense something\n",
    "\n",
    "* Neuron (noun) a nerve cell in the human brain that turns sensory input into meaningful information\n",
    "\n",
    "Therefore, the perceptron is an artificial neuron that simulates the task of a biological neuron to solve problems through its own “sense” of the world.\n",
    "\n",
    "Although the perceptron comes with its own artificial design and set of parameters, at its core, a single perceptron is trying to make a simple decision.\n",
    "\n",
    "Let’s take the example a simple self-driving car that is based on a perceptron. If there’s an obstacle on the left, the car would have to steer right. Similarly, if there’s an obstacle on the right, the car would have to steer left.\n",
    "\n",
    "For this example, a perceptron could take the position of the obstacle as inputs, and produce a decision — left turn or right turn — based on those inputs.\n",
    "\n",
    "And here’s the cool part — the perceptron can correct itself based on the result of its decision to make better decisions in the future!\n",
    "\n",
    "Of course, the real world scenario isn’t that simple. But if you combine a bunch of such perceptrons, you will get a neural network that can even make better decisions on your behalf!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/perceptron.png\" width=\"800\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing a Perceptron\n",
    "So the perceptron is an artificial neuron that can make a simple decision. Let’s implement one from scratch in Python!\n",
    "\n",
    "The perceptron has three main components:\n",
    "\n",
    "Inputs: Each input corresponds to a feature. For example, in the case of a person, features could be age, height, weight, college degree, etc.\n",
    "\n",
    "* Weights: Each input also has a weight which assigns a certain amount of importance to the input. If an input’s weight is large, it means this input plays a bigger role in determining the output. For example, a team’s skill level will have a bigger weight than the average age of players in determining the outcome of a match.\n",
    "\n",
    "\n",
    "* Output: Finally, the perceptron uses the inputs and weights to produce an output. The type of the output varies depending on the nature of the problem. For example, to predict whether or not it’s going to rain, the output has to be binary — 1 for Yes and 0 for No. However, to predict the temperature for the next day, the range of the output has to be larger — say a number from 70 to 90."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Our Perceptron class by default takes two inputs and a pre-defined weight for each input.\n",
    "\n",
    "Complete the __init__() method inside the Perceptron class by creating instance variables self.num_inputs and self.weights that represent the attributes of a Perceptron object.\n",
    "\n",
    "Assign the parameters num_inputs and weights to self.num_inputs and self.weights respectively.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "\n",
    "\n",
    "2.\n",
    "Create a Perceptron object called cool_perceptron (without any arguments) and print it out to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Perceptron object at 0x000002BCAA0ED080>\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    # complete the default constructor method\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "  \n",
    "\n",
    "    \n",
    "    \n",
    "cool_perceptron =  Perceptron()\n",
    "\n",
    "print(cool_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Weighted Sum\n",
    "\n",
    "Great! Now that you understand the structure of the perceptron, here’s an important question — how are the inputs and weights magically turned into an output? This is a two-step process, and the first step is finding the weighted sum of the inputs.\n",
    "\n",
    "What is the weighted sum? This is just a number that gives a reasonable representation of the inputs:\n",
    "\n",
    "$weighted\\ sum = x_1w_1 + x_2w_2 + ... + x_nw_n $\n",
    "\n",
    "The x‘s are the inputs and the w‘s are the weights.\n",
    "\n",
    "Here’s how we can implement it:\n",
    "\n",
    "* Start with a weighted sum of 0. Let’s call it weighted_sum.\n",
    "\n",
    "* Start with the first input and multiply it by its corresponding weight. Add this result to weighted_sum.\n",
    "\n",
    "* Go to the next input and multiply it by its corresponding weight. Add this result to weighted_sum.\n",
    "\n",
    "* Repeat this process for all inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Create a variable called weighted_sum to hold the value of the weighted sum and set its starting value to 0.\n",
    "\n",
    "Return weighted_sum outside the for loop.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "\n",
    "\n",
    "2.\n",
    "Let’s go through each input-weight pair and find the weighted sum using indexing.\n",
    "\n",
    "Delete the pass statement inside the for loop. For each iteration in the loop, find the product of the input and weight at index i, add the result to weighted_sum, and store it back in weighted_sum to update the value of weighted_sum.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "\n",
    "\n",
    "3.\n",
    "Outside the Perceptron class, after the Perceptron object cool_perceptron has been created, print out the weighted sum for the inputs [24, 55].\n",
    "\n",
    "What is the weighted sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[2,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    # create variable to store weighted sum\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum +=   self.weights[i] * inputs[i]\n",
    "    return weighted_sum\n",
    "      # complete this loop\n",
    "      \n",
    "cool_perceptron = Perceptron()\n",
    "\n",
    "print(cool_perceptron.weighted_sum([24,55]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Activation Function\n",
    "\n",
    "After finding the weighted sum, the second step is to constrain the weighted sum to produce a desired output.\n",
    "\n",
    "Why is that important? Imagine if a perceptron had inputs in the range of 100-1000 but the goal was to simply predict whether or not something would occur — 1 for “Yes” and 0 for “No”. This would result in a very large weighted sum.\n",
    "\n",
    "How can the perceptron produce a meaningful output in this case? This is exactly where activation functions come in! These are special functions that transform the weighted sum into a desired and constrained output.\n",
    "\n",
    "For example, if you want to train a perceptron to detect whether a point is above or below a line (which we will be doing in this lesson!), you might want the output to be a +1 or -1 label. For this task, you can use the “sign activation function” to help the perceptron make the decision:\n",
    "\n",
    "    If weighted sum is positive, return +1\n",
    "    If weighted sum is negative, return -1\n",
    "In this lesson, we will focus on using the sign activation function because it is the simplest way to get started with perceptrons and eventually visualize one in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "Inside the .activation() method, return 1 if the weighted_sum is greater than or equal to 0.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "\n",
    "\n",
    "2.\n",
    "Inside the .activation() method, return -1 if the weighted_sum is less than 0.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "\n",
    "\n",
    "3.\n",
    "Try it out for yourself!\n",
    "\n",
    "Print out the result of the method .activation() called on cool_perceptron if the weighted sum is 52."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "  \n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >=0:\n",
    "      return 1\n",
    "    else:\n",
    "      return -1\n",
    "    #Complete this method\n",
    "\n",
    "cool_perceptron = Perceptron()\n",
    "print(cool_perceptron.weighted_sum([24, 55]))\n",
    "\n",
    "print(cool_perceptron.activation(52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Perceptron\n",
    "\n",
    "Our perceptron can now make a prediction given inputs, but how do we know if it gets those predictions right?\n",
    "\n",
    "Right now we expect the perceptron to be very bad because it has random weights. We haven’t taught it anything yet, so we can’t expect it to get classifications correct! The good news is that we can train the perceptron to produce better and better results! In order to do this, we provide the perceptron a training set — a collection of random inputs with correctly predicted outputs.\n",
    "\n",
    "On the right, you can see a plot of scattered points with positive and negative labels. This is a simple training set.\n",
    "\n",
    "In the code, the training set has been represented as a dictionary with coordinates as keys and labels as values. For example:\n",
    "\n",
    "    training_set = {(18, 49): -1, (2, 17): 1, (24, 35): -1, (14, 26): 1, (17, 34): -1}\n",
    "    \n",
    "    \n",
    "We can measure the perceptron’s actual performance against this training set. By doing so, we get a sense of “how bad” the perceptron is. The goal is to gradually nudge the perceptron — by slightly changing its weights — towards a better version of itself that correctly matches all the input-output pairs in the training set.\n",
    "\n",
    "We will use these points to train the perceptron to correctly separate the positive labels from the negative labels by visualizing the perceptron as a line. Stay tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def generate_training_set(num_points):\n",
    "    x_coordinates = [random.randint(0, 50) for i in range(num_points)]\n",
    "    y_coordinates = [random.randint(0, 50) for i in range(num_points)]\n",
    "    training_set = dict()\n",
    "    for x, y in zip(x_coordinates, y_coordinates):\n",
    "        if x <= 45-y:\n",
    "            training_set[(x,y)] = 1\n",
    "        elif x > 45-y:\n",
    "            training_set[(x,y)] = -1\n",
    "    return training_set\n",
    "\n",
    "training_set = generate_training_set(30)\n",
    "\n",
    "x_plus = []\n",
    "y_plus = []\n",
    "x_minus = []\n",
    "y_minus = []\n",
    "\n",
    "for data in training_set:\n",
    "    if training_set[data] == 1:\n",
    "        x_plus.append(data[0])\n",
    "        y_plus.append(data[1])\n",
    "    elif training_set[data] == -1:\n",
    "        x_minus.append(data[0])\n",
    "        y_minus.append(data[1])\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(-25, 75), ylim=(-25, 75))\n",
    "\n",
    "plt.scatter(x_plus, y_plus, marker = '+', c = 'green', s = 128, linewidth = 2)\n",
    "plt.scatter(x_minus, y_minus, marker = '_', c = 'red', s = 128, linewidth = 2)\n",
    "\n",
    "plt.title(\"Training Set\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Error\n",
    "\n",
    "Now that we have our training set, we can start feeding inputs into the perceptron and comparing the actual outputs against the expected labels!\n",
    "\n",
    "Every time the output mismatches the expected label, we say that the perceptron has made a training error — a quantity that measures “how bad” the perceptron is performing.\n",
    "\n",
    "As mentioned in the last exercise, the goal is to nudge the perceptron towards zero training error. The training error is calculated by subtracting the predicted label value from the actual label value.\n",
    "\n",
    "$training\\ error = actual\\ label - predicted\\ label$\n",
    "\n",
    "\n",
    "For each point in the training set, the perceptron either produces a +1 or a -1 (as we are using the Sign Activation Function). Since the labels are also a +1 or a -1, there are four different possibilities for the error the perceptron makes:\n",
    "\n",
    "|Actual|\tPredicted|\tTraining Error|\n",
    "|---|---|---|\n",
    "|+1\t|+1|0 |\n",
    "|+1 |-1|2 |\n",
    "|-1 |-1| 0|\n",
    "|-1\t|+1|-2|\n",
    "\n",
    "These training error values will be crucial in improving the perceptron’s performance as we will see in the upcoming exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "In the .training() method, let’s find the perceptron’s error on each inputs in training_set.\n",
    "\n",
    "    First, we need the perceptron’s predicted output for a point. Inside the for loop, create a variable called prediction and assign it the correct label value using .activation(), .weighted_sum(), and inputs in a single statement.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "\n",
    "\n",
    "2.\n",
    "Create a variable named actual and assign it the actual label for each inputs in training_set.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "\n",
    "\n",
    "3.\n",
    "Create a variable called error and assign it the value of actual - prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "1\n",
      "0 -2 0 -2 0 -2 0 -2 0 -2 0 -2 -2 0 -2 0 -2 0 -2 -2 0 0 -2 0 -2 -2 -2 0 -2 -2 "
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "  \n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >= 0:\n",
    "      return 1\n",
    "    if weighted_sum < 0:\n",
    "      return -1\n",
    "    \n",
    "  def training(self, training_set):\n",
    "    for inputs in training_set:                   \n",
    "      prediction = self.activation(self.weighted_sum(inputs))\n",
    "      actual = training_set[inputs]\n",
    "      error = actual - prediction\n",
    "    return error\n",
    "      \n",
    "cool_perceptron = Perceptron()\n",
    "print(cool_perceptron.weighted_sum([24, 55]))\n",
    "print(cool_perceptron.activation(52))\n",
    "for i in range(30):\n",
    "     print(cool_perceptron.training(generate_training_set(30)), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweaking the Weights\n",
    "\n",
    "What do we do once we have the errors for the perceptron? We slowly nudge the perceptron towards a better version of itself that eventually has zero error.\n",
    "\n",
    "The only way to do that is to change the parameters that define the perceptron. We can’t change the inputs so the only thing that can be tweaked are the weights. As we change the weights, the outputs change as well.\n",
    "\n",
    "The goal is to find the optimal combination of weights that will produce the correct output for as many points as possible in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/yk1mk.png\" width=\"600\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron Algorithm\n",
    "\n",
    "But one question still remains — how do we tweak the weights optimally? We can’t just play around randomly with the weights until the correct combination magically pops up. There needs to be a way to guarantee that the perceptron improves its performance over time.\n",
    "\n",
    "This is where the Perceptron Algorithm comes in. The math behind why this works is outside the scope of this lesson, so we’ll directly apply the algorithm to optimally tweak the weights and nudge the perceptron towards zero error.\n",
    "\n",
    "The most important part of the algorithm is the update rule where the weights get updated:\n",
    "\n",
    "weight = weight + (error * input)weight=weight+(error∗input)\n",
    "We keep on tweaking the weights until all possible labels are correctly predicted by the perceptron. This means that multiple passes might need to be made through the training_set before the Perceptron Algorithm comes to a halt.\n",
    "\n",
    "In this exercise, you will continue to work on the .training() method. We have made the following changes to this method from the last exercise:\n",
    "\n",
    "* foundLine = False (a boolean that indicates whether the perceptron has found a line to separate the positive and negative labels)\n",
    "\n",
    "* while not foundLine: (a while loop that continues to train the perceptron until the line is found)\n",
    "\n",
    "* total_error = 0 (to count the total error the perceptron makes in each round)\n",
    "\n",
    "* total_error += abs(error) (to update the total error the perceptron makes in each round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "1.\n",
    "If the algorithm doesn’t find an error, the perceptron must have correctly predicted the labels for all points.\n",
    "\n",
    "Outside the for loop (but inside the while loop), change the value of foundLine to True if total_error equals 0.\n",
    "\n",
    "Checkpoint 2 Passed\n",
    "\n",
    "\n",
    "2.\n",
    "In order to update the weight for each inputs, create another for loop (inside the existing for loop) that iterates a loop variable i through a range of self.num_inputs.\n",
    "\n",
    "Checkpoint 3 Passed\n",
    "\n",
    "\n",
    "3.\n",
    "Inside the second for loop, update each weight self.weights[i] by applying the update rule:\n",
    "\n",
    "weight = weight + (error * inputs)weight=weight+(error∗inputs)\n",
    "Checkpoint 4 Passed\n",
    "\n",
    "\n",
    "4.\n",
    "Great job! Now give it a try for yourself.\n",
    "\n",
    "Train cool_perceptron using small_training_set.\n",
    "\n",
    "You can also print out the optimal weights to see for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5, 1]\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=2, weights=[1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "  \n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >= 0:\n",
    "      return 1\n",
    "    if weighted_sum < 0:\n",
    "      return -1\n",
    "    \n",
    "  def training(self, training_set):\n",
    "    foundLine = False\n",
    "    while not foundLine:\n",
    "      total_error = 0\n",
    "      for inputs in training_set:\n",
    "        prediction = self.activation(self.weighted_sum(inputs))\n",
    "        actual = training_set[inputs]\n",
    "        error = actual - prediction\n",
    "        total_error += abs(error)\n",
    "        for i in range(self.num_inputs):\n",
    "          self.weights[i] += error*inputs[i]\n",
    "        \n",
    "        \n",
    "      if total_error == 0:\n",
    "        foundLine = True\n",
    "      \n",
    "cool_perceptron = Perceptron()\n",
    "small_training_set = {(0,3):1, (3,0):-1, (0,-3):-1, (-3,0):1}\n",
    "cool_perceptron.training(small_training_set)\n",
    "print(cool_perceptron.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bias Weight\n",
    "You have understood that the perceptron can be trained to produce correct outputs by tweaking the regular weights.\n",
    "\n",
    "However, there are times when a minor adjustment is needed for the perceptron to be more accurate. This supporting role is played by the bias weight. It takes a default input value of 1 and some random weight value.\n",
    "\n",
    "So now the weighted sum equation should look like:\n",
    "\n",
    "$weighted\\ sum = x_1w_1 + x_2w_2 + ... + x_nw_n + 1w_b$ \n",
    "\n",
    "How does this change the code so far? You only have to consider two small changes:\n",
    "\n",
    "* Add a 1 to the set of inputs (now there are 3 inputs instead of 2)\n",
    "\n",
    "* Add a bias weight to the list of weights (now there are 3 weights instead of 2)\n",
    "\n",
    "We’ll automatically make these replacements in the code so you should be good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=3, weights=[1,1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "    \n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "  \n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >= 0:\n",
    "      return 1\n",
    "    if weighted_sum < 0:\n",
    "      return -1\n",
    "    \n",
    "  def training(self, training_set):\n",
    "    foundLine = False\n",
    "    while not foundLine:\n",
    "      total_error = 0\n",
    "      for inputs in training_set:\n",
    "        prediction = self.activation(self.weighted_sum(inputs))\n",
    "        actual = training_set[inputs]\n",
    "        error = actual - prediction\n",
    "        total_error += abs(error)\n",
    "        for i in range(self.num_inputs):\n",
    "          self.weights[i] += error*inputs[i]\n",
    "      if total_error == 0:\n",
    "        foundLine = True\n",
    "      \n",
    "cool_perceptron = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing a Line\n",
    "\n",
    "So far so good! The perceptron works as expected, but everything seems to be taking place behind the scenes. What if we could visualize the perceptron’s training process to gain a better understanding of what’s going on?\n",
    "\n",
    "The weights change throughout the training process so if only we could meaningfully visualize those weights…\n",
    "\n",
    "Turns out we can! In fact, it gets better. The weights can actually be used to represent a line! This greatly simplifies our visualization.\n",
    "\n",
    "You might know that a line can be represented using the slope-intercept form. A perceptron’s weights can be used to find the slope and intercept of the line that the perceptron represents.\n",
    "\n",
    "    slope = -self.weights[0]/self.weights[1]\n",
    "    \n",
    "    intercept = -self.weights[2]/self.weights[1]\n",
    "    \n",
    "The explanation for these equations is beyond the scope of this lesson, so we’ll just use them to visualize the perceptron for now.\n",
    "\n",
    "In the plot on your right, you should be able to see a line that represents the perceptron in its first iteration of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "class Perceptron:\n",
    "  def __init__(self, num_inputs=3, weights=[1,1,1]):\n",
    "    self.num_inputs = num_inputs\n",
    "    self.weights = weights\n",
    "\n",
    "  def weighted_sum(self, inputs):\n",
    "    weighted_sum = 0\n",
    "    for i in range(self.num_inputs):\n",
    "      weighted_sum += self.weights[i]*inputs[i]\n",
    "    return weighted_sum\n",
    "\n",
    "  def activation(self, weighted_sum):\n",
    "    if weighted_sum >= 0:\n",
    "      return 1\n",
    "    if weighted_sum < 0:\n",
    "      return -1\n",
    "\n",
    "  def training(self, training_set):\n",
    "    foundLine = False\n",
    "    while not foundLine:\n",
    "      total_error = 0\n",
    "      for inputs in training_set:\n",
    "        prediction = self.activation(self.weighted_sum(inputs))\n",
    "        actual = training_set[inputs]\n",
    "        error = actual - prediction\n",
    "        total_error += abs(error)\n",
    "        for i in range(self.num_inputs):\n",
    "          self.weights[i] += error*inputs[i]\n",
    "\n",
    "      # just add the slope and intercept  \n",
    "      slope = -self.weights[0]/self.weights[1]\n",
    "      intercept = -self.weights[2]/self.weights[1]\n",
    "      y1 = (slope * 0) + intercept\n",
    "      y2 = (slope * 50) + intercept\n",
    "      lines.append([[0,50], [y1, y2]])\n",
    "\n",
    "      if total_error == 0:\n",
    "        foundLine = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEICAYAAAC6fYRZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAVPUlEQVR4nO3dfZAU9Z3H8U93z8wKgoKwPCMLhQpYMSoo3GGigkQUs0RFMSChCLhHIh6I8UIdF0/uYljMKXKYaDbnAyEQjFxFKNA1FzjJgRGKiBqFmKUUZRFheZJH56H7d380OjwssLszs8z+5v2qooqdnu3+9W97Pv2dXz85ZlWREQDASu7ZbgAAIHcIeQCwGCEPABYj5AHAYoQ8AFiMkAcAixHyQB21GBrXB59wxjGaFkIeTULJyLj+sD6QJD3/iq9rJiVyurzrJif0X8v84147WFmkHp2cnC5XkvbsN7p1elLn3hhXtzvjWvg//pl/CTiFyNluANDYUimjSCT3Yd1Q985OKRaVdvwuprc2Gw2bltRXezq6tDs1GeqPrQZNyqYtgSY+ntKf3jNqMTSuVsPikqR4wugHP0/pwjviav+tuCY+ltSReDi08tqGQF1GxDVrYUodbo1rXHlKew8Y3TItqeLSuFoPi+uWaUlV7wzfP/2XKf3fO0aT5qTUYmhck55ISpKca+PaXB2+57ODRt95JPz9bnfG9eNfpRQE4bQvvmn84OcptR4WV/eRcb3yRt2q8UNHjP77j4H+fbynFs0dXXOZq9K/dzX/90FW+xGFg5BHk9K7xNXTUyP6u0sdHaws0r7lRZKkH/7C19+2Gr31TEybF8a0rUb6t3npYP10j7Rnv/TRCzFVPBhREEjjbnL10W9j+vjFmJrFpElzUpKkR+6J6GuXOXpyckQHK4v05JToSe24b05Knx2SPlgU06o5Mf3q1UDPvZIO4rUbjS7p6mjX0pj+6dsRjX80JWPCnUD5gpRumZasdf3+ttXIc6WLu6Y/ml/t6ei9DzkWgIYh5NHkGWP0y2W+Zk+K6ILzHLVs7uif7/a0aEU65F1HmjHOU1HMUbMiR23Od3T7tZ6anxO+f/oYT6veqlu17PtGL/xvoJllnlo2d1TS0dEDIz3N/316ed06SPd805PnORo71NX23dKOPeG0aaMjWlZ+8o5Dkg4ekc5vcfxr55/r6MARQh4Nw5g8mryafdLhz6W+ZemDscZI/jGZXdxKOqcoPQ5/+HOj+59MqXJdoL0HwtcOHA4D3PNOP16/6zMpkZS6tU+/r1t7R9tq0u/pcEF6WvNzwv8fPHLmdWnRTNp/6PjX9h82atksf48hIL8R8mhynBPyru35UrMi6b3nY+pcXHsYnvg7j73g6/2tRmufiqlDG0dvVQW6YkJSR0dUdLpIbXu+FI1IH+0w6lMSvvPjHUadixu4Qse4uKujlC9VVQe6qEv4RfvtzUaXdifk0TAM16DJad/aUXWNUSIZJrLrOrrnFk/3P5nSzr3ha9tqjF5dd+rhlwOHpWYxqVWL8JTFGc8ff2C0/QXOKc+J9zxHd17vavovfR04bPTRp0aPv+jr7iFexut2bjNHt33d1UPP+Dp0xGjNXwItWRNozDf4qKJh2HLQ5Ay60tGlJa463JpQ29Lw7JpZ/+CpZ2dHA76X0Hk3xXXD1KTe//jUIT/lDk9HElLb4QkN+F5SQ/sf/1GYfLunxasCtR4W1z8ePSB7rLmTIzq3mdTjroSumZTQqMGuvntz3T5OP5mf0k0Pnvo8/5/fH9GRhNTuWwl9+9+Seur+CKdPosEcHhoCAPaiPAAAixHyAGAxQh4ALEbIA4DF8uo8+ba3tVBJScnZbgYANClbNv9Zu5YW1Totr0K+pKRE69evP9vNAIAmpV+vUw/KMFwDABYj5AHAYoQ8AFiMkAcAixHyAGAxQh4ALEbIA4DFCHkAsBghDwAWI+QBwGKEPABYjJAHAIsR8gBgMUIeACxGyAOAxQh5ALAYIQ8AFiPkAcBihDwAWIyQBwCLEfIAYDFCHgAsRsgDgMUIeQCwGCEPABYj5AHAYoQ8AFiMkAcAi2Ul5PcdMBrxUFK9xiTUe0xCf3o30J79RkOmJnTRqISGTE1o7wGTjUUBAOohKyE/eW5KQ6929df5Mb39bFS9uzkqX+BrcF9XVQtjGtzXVfkCPxuLAgDUQ8Yhv/+Q0R/fDjR+WDirWNRRq5aOlqwJNHaoJ0kaO9TTS6uDTBcFAKinSKYz+OATo+JWjsaVp/T2ZqO+lziac19EO/YadWzjSJI6tnG0c2/twzUVS31VLAur/JojNZk2BwBwjIwr+ZQvvVll9L3hnjY8E9O55zgqX1j3oZmyUk/rK2JaXxFTcXFxps0BABwj45DvUuyoS7HUv084qxHXunrzb0btWzvavjus3rfvNmrX2sl0UQCAeso45Du0cdS12NH7H4dj7iveDNSnxFHpQFfzKsOKfl6lr+EDOVsTABpbxmPykjR3ckSjf5xSIin16OTouWkRBYF058NJPbM8oQvbSy/OiGZjUQCAeshKyF9+kav1FbGTXl8x++TXAACNhzEUALAYIQ8AFiPkAcBihDwAWIyQBwCLEfIAYDFCHgAsRsgDgMUIeQCwGCEPABYj5AHAYoQ8AFiMkAcAixHyAGAxQh4ALJaV+8kDJ3Hq+bhHU/uD3gFkhkoeACxGJY/coDKHxDe6PEAlDwAWo5IHkDtU5mcdlTwAWIyQBwCLEfIAYDHG5AFbcCYLakElDwAWo5IHbEFljlpQyQOAxQj5AuDMcOTMqOd4LQArEPIAYDFCHgAsxoFX5CdOBwSygkoeACxGJW+Z0x1grW2a+dc8rYCpzIGsoJIHAItlrZL3faN+ZUl1Lna0rDyqD7cb3TUjqT37pSsvdjR/ekSxKKfx5VptlfkXFXzeVu0AciZrlfycxb56d0uH+A+fTun+OzxVLYypdUvpmeVBthYFAKijrIR89U6j5W8EmnCLJ0kyxmjlhkAjrg1nP/ZGTy+t9rOxKABAPWRluGbKkyk9OjGiA4fDn3d/JrVqIUUiYWXfpZ2jbbtq/92Kpb4qloU7gJojNdloDgDgqIwr+WWv+2rXSup7SXpWtY38nmo0vqzU0/qKmNZXxFRcXJxpcwAAx8i4kl/zrtHS1wO9vDauzxPS/kPSlLkp7TsopVJGkYij6p1Gndpmo7loCA64os6ycREaF7LllYwr+ZllEVUvLtKWF4q06KGoBl3pasGPorr+cleLV4UHW+e96mv4QC/jxgIA6idn58nPmhjR47/11XNUXLs/k8YP45R8IO8ZU79/uZoHsiarV7xed4Wr664Iw7xHJ0frfhHL5uwBAPVEeQ0AFiPkAcBihDwAWIyQBwCLEfIAYDFCHgAsRsgDgMV4MhSAuuF2BU0SlTxyxpnhHPfIwRN/BpB7VPIA6obKvEmikgcAixHyAGAxQh4ALMaYPLLidAdUT5xW23vP+GATzuwAGoRKHgAsRiWPrKitEv+iYv9i2ok/128BVOZAQ1DJA4DFCHkAsBghDwAWI+QBwGIceEXOnHiAtUEHXG2Q6emfnD6KDFDJA4DFqOSBXMu0sqYyRwao5AHAYoQ8AFiMkAcAixHyAGAxQh4ALEbII6t4jiuQXwh5ALAYIQ8AFiPkAcBihDxQBxxrQFPFbQ3QYPV5rqtUQDco44ZiyCNU8gBgsYwr+a07jb7zSFKf7pFcVyr7pqvJIyLas99o5MNJbflUKukg/XZGVK1b8nXXJnV5rmtBojJHHsm4ko940mP3RrRpfkxvPBXVz34XaOOWQOULfA3u66pqYUyD+7oqX+Bno73IMsaaAbtlXMl3bOOoY5swJFo2d9S7m6NtNdKSNYFemxOVJI0d6um6yUnNmpjp0oDcy7tjDYzxIwNZPfC6ZbvRhqpA/ftEtGOv+TL8O7ZxtHNv7RtexVJfFcvCKr/mSE02mwMABS9rIX/wsNHtDyX1xH0RnXdu3SuPslJPZaWeJKnf1OJsNQdosLw71kBljgxkJeSTqTDgR9/g6ravh4HdvrWj7bvDan77bqN2rRn3LQQFfcAVyEMZh7wxRuNnpdS7m6upI9OzKx3oal6lr2mjI5pX6Wv4QM7WPNvybqwZQM5lHPJr/mI0//eBvtLD0eXjE5Kkn9zjadooT3c+nNQzyxO6sL304oxoxo0FANRPxiF/zWWuzKqiWqetmB3LdPbIorwbawaQc9zWAKgDdoJoqhgoB3LkdBeacREaGgshDwAWI+RhvbpWzVTXsBFj8gWOsWbAblTyKGhU77AdlTyQBfW90Ox00/h2hWyikgcAi1HJwyrZqKgbUl3X90KzJn8RGrc/bjKo5AHAYlTyqLd8rkJPVzVnY144isq8yaCSBwCLUcmjYJxpbDyfv6EADUXIAznCzgL5gOEaNBouPAIaH5U8TsuGC3nq2qZctd2GPkTTRSUPABajksdpWXkhzzEaYx1s70PkNyp5ALAYlTxygnHoPMCtByAqeQCwGpU8coJx6DxAZQ4R8mgAQjpz9CEaC8M1AGAxQh4ALEbIA4DFGJNHo2EcGmh8VPJAFnETNuQbQh4ALEbII6uoZIH8QsgDgMUIeQCwGGfXAA3ETdjQFFDJA4DFcl7JV64NNHluSn5gNGGYp2mj+fJgi0KvZLkJG5qCnFbyvm907xNJvfJoVBvnxfSbFYE2bglyuUgAwDFyWlav22TUs7OjHp3C6uauQa6WrA7Up4RRIhtQyQL5L6chv22XUdd26a/tXYodrd10fCVfsdRXxTJfklRzpCaXzQGAgpPTkK/tmQUnjtSWlXoqK/UkSf2mFueyOQBQcHIa8l2KHW3dmU766hqjTm25GhL2YpgK+Sang+NX9XJUVW304XajRNJo0cpApQMZjweAxpLTSj4ScfTklIhu/EFSfmD03Zs9XdqdkLcZlSyQX3J+0vrNAzzdPMDL9WIAALWgrAYAixHyAGAxQh4ALEbIA4DFCHkAsBghDwAWI+QBwGKEPABYjJAHAIsR8gBgMUIeACxGyAOAxQh5ALAYIQ8AFiPkAcBihDwAWIyQBwCLEfIAYDFCHgAsRsgDgMUIeQCwGCEPABYj5AHAYoQ8AFiMkAcAixHyAGAxQh4ALEbIA4DFCHkAsBghDwAWI+QBwGKEPABYjJAHAIsR8gBgMUIeACyWUcg/+FRKvcYkdNm4hG6dntS+A+bLaTN/nVLPUXFdcndCr64LMm4oAKD+Mgr5If1cvftcVO88F9PFXR3NXOBLkjZuCbRoZaD3no+p8qdRfX92Ur5vzjA3AEC2ZRTy37jKVSTiSJIG9HFUXRMG+ZLVge4a5Koo5qh7R0c9Oztat4mQB4DGFsnWjJ59OdDIQeE+Y9suowF90vuPLsWOtu2qPeQrlvqqWBZ+A6g5UpOt5gAAVIeQv2FqQp/uOfn1RyZ4Gn6NF/5/fkoRTxo9JAx2U0ueO07t8y8r9VRWGs6n39TiOjYbAFAXZwz5PzweO+30eZW+lr0eaMXsqJyjSd6l2NHWnemkr64x6tTmFCkPAMiZjMbkK9cGmrXQ19KZUTU/Jx3ipQNdLVoZKJ4w+nC7UVW10dW9CXkAaGwZjclPmpNUPCENeSApKTz4+vQDUV3a3dWd17vqMzahiOfoZ1Mi8jxCHgAaW0Yhv3lh0SmnTR8T0fQxWTuuCwBoAK54BQCLEfIAYDFCHgAsRsgDgMUIeQCwWF6d/rJl85/Vr1dm+52afUbFrThdU6IvjkVfpNEXabb0xZZPT31vMMesKrLqzmH9yhJaX3H6q3QLBX2RRl+k0RdphdAXDNcAgMUIeQCwmPfwuMjDZ7sRWWWkvpew75JEXxyLvkijL9IKoC+sG5MHAKTZvQsDgAJHyAOAxawJ+QefSqnXmIQuG5fQrdOT2ncgPQo189cp9RwV1yV3J/TquuAstrJxVK4NdMndCfUcFVf5gtTZbk6j2rrT6PrJCfUek9ClYxOaszhc/z37jYZMTeiiUQkNmZrQ3gOFM0rp+0ZXjE/olmnhLcE/3G7Uf2LYFyMfTiqRLIy+2HfAaMRDSfUaE24ff3o3KIjtwpqQH9LP1bvPRfXOczFd3NXRzAXhc2M3bgm0aGWg956PqfKnUX1/dlK+b98f8gu+b3TvE0m98mhUG+fF9JsVgTZusX/H9oWIJz12b0Sb5sf0xlNR/ex34fqXL/A1uK+rqoUxDe7rqvzo9lEI5iz21btb+oKfHz6d0v13eKpaGFPrltIzywtj+5g8N6WhV7v66/yY3n42qt7dnILYLqwJ+W9c5SoSCTfkAX0cVdeEQb5kdaC7Brkqijnq3tFRz86O1m2yN+TXbTLq2dlRj06OYlFHdw1ytWR1YXyIJaljG0dXXhxu1i2bO+rdzdG2GmnJmkBjh4bPEh471NNLBdIn1TuNlr8RaMIt4bobY7RyQ6AR14Z9NPZGTy+tti/YTrT/kNEf3w40fli43rGoo1YtnYLYLqwJ+WM9+3Kgm/qHq7Ztl1HXdukqpkuxo2277A35Qlvf09my3WhDVaD+fRzt2GvU8ehzhju2cbRzb2H0yZQnU3p0YkTu0U1i92dSqxb6siDq0s7Rtl1nsYGN5INPwtsXjCtP6YrxCU14NKlDR0xBbBd5de+aM7lhakKf7jn59UcmeBp+Tbg3fmR+ShFPGj0kDHlTy9/Mafq3qjilWte38Ztx1h08bHT7Q0k9cV9E551biD0gLXvdV7tW4Xngr20IK9TaIqwQeiflS29WGc2dHFH/Pq4m/2dK5Qvt/wYjNbGQ/8Pjp7/HxLxKX8teD7RidlTO0STvUuxo6870pl1dY9Spjb2bda3r29be9a1NMhUG/OgbXN329XDn3761o+27w6pt+26jdq3t75M17xotfT3Qy2vj+jwh7T8kTZmb0r6DUiplFIk4qt5p1Knt2W5p7nUpdtSlWOrfJyz+RlzrqnyhXxDbhTXDNZVrA81a6GvpzKian5P+Q5UOdLVoZaB4wujD7UZV1UZX97bvD/mFq3o5qqoO1zWRNFq0MlDpQGv+zGdkjNH4WSn17uZq6sh0DVM60NW8yrBym1fpa3gB9MnMsoiqFxdpywtFWvRQVIOudLXgR1Fdf7mrxavCyn7eq76GD/TOcktzr0MbR12LHb3/cbjeK94M1KfEKYjtwporXnuOiiuekNqcnz74+vQDUUnhEM6zL/uKeI6emOTppgF2b9Qvv+FrylxffmD03Zu9gnqg+up3An3tvqS+0sORe/Tz+pN7PPXv7erOh5P6eId0YXvpxRlRXXCevTv7E722IdB/vOBrWXlUH3xidNeMpPYcMLqip6tf/0tERTH7++KtqkATfppSIin16OTouWkRBYGs3y6sCXkAwMns+24CAPgSIQ8AFiPkAcBihDwAWIyQBwCLEfIAYDFCHgAs9v9JMNTRsaTcxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "#from perceptron import Perceptron, lines\n",
    "\n",
    "def generate_training_set(num_points):\n",
    "    x_coordinates = [random.randint(0, 50) for i in range(num_points)]\n",
    "    y_coordinates = [random.randint(0, 50) for i in range(num_points)]\n",
    "    training_set = dict()\n",
    "    for x, y in zip(x_coordinates, y_coordinates):\n",
    "        if x <= 45-y:\n",
    "            training_set[(x,y,1)] = 1\n",
    "        elif x > 45-y:\n",
    "            training_set[(x,y,1)] = -1\n",
    "    return training_set\n",
    "\n",
    "training_set = generate_training_set(30)\n",
    "\n",
    "x_plus = []\n",
    "y_plus = []\n",
    "x_minus = []\n",
    "y_minus = []\n",
    "\n",
    "for data in training_set:\n",
    "    if training_set[data] == 1:\n",
    "        x_plus.append(data[0])\n",
    "        y_plus.append(data[1])\n",
    "    elif training_set[data] == -1:\n",
    "        x_minus.append(data[0])\n",
    "        y_minus.append(data[1])\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.training(training_set)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(-25, 75), ylim=(-25, 75))\n",
    "line, = ax.plot([], [], lw=2)\n",
    "\n",
    "fig.patch.set_facecolor('#ffc107')\n",
    "\n",
    "plt.scatter(x_plus, y_plus, marker = '+', c = 'green', s = 128, linewidth = 2)\n",
    "plt.scatter(x_minus, y_minus, marker = '_', c = 'red', s = 128, linewidth = 2)\n",
    "\n",
    "plt.title('Iteration: 0')\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    print(i)\n",
    "    line.set_xdata(lines[i][0])  # update the data\n",
    "    line.set_ydata(lines[i][1])  # update the data\n",
    "    return line,\n",
    "\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return line,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=1, init_func=init, interval=50, blit=True, repeat=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a Linear Classifier\n",
    "\n",
    "Let’s recap what you just learned!\n",
    "\n",
    "The perceptron has inputs, weights, and an output. The weights are parameters that define the perceptron and they can be used to represent a line. In other words, the perceptron can be visualized as a line.\n",
    "\n",
    "What does it mean for the perceptron to correctly classify every point in the training set?\n",
    "\n",
    "Theoretically, it means that the perceptron predicted every label correctly.\n",
    "\n",
    "Visually, it means that the perceptron found a linear classifier, or a decision boundary, that separates the two distinct set of points in the training set.\n",
    "\n",
    "In the plot on the right, you should be able to see the linear classifier that was found by the perceptron in the last iteration of the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/otA0O3u.gif\" width=\"600\" height=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Next? Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "Let’s step back and think about what you just accomplished and see if there are any limits to a single perceptron.\n",
    "\n",
    "Earlier, the data points in the training set were linearly separable i.e. a single line could easily separate the two dissimilar sets of points.\n",
    "\n",
    "What would happen if the data points were scattered in such a way that a line could no longer classify the points? A single perceptron with only two inputs wouldn’t work for such a scenario because it cannot represent a non-linear decision boundary.\n",
    "\n",
    "That’s when more perceptrons and features come into play!\n",
    "\n",
    "By increasing the number of features and perceptrons, we can give rise to the Multilayer Perceptrons, also known as Neural Networks, which can solve much more complicated problems.\n",
    "\n",
    "With a solid understanding of perceptrons, you are now ready to dive into the incredible world of Neural Networks!\n",
    "\n",
    "<img src=\"images/neural-net-image.svg\" width=\"800\" height=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
